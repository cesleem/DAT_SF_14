{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://files.obshandinhand.webnode.nl/200000026-f2e8cf3e1e/200000000.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://files.obshandinhand.webnode.nl/200000026-f2e8cf3e1e/200000000.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mine the Gap: Targeting High Risk Patients for Care Coordination & Social Support Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook originally appeared as a [post](http://jakevdp.github.io/blog/2014/11/11/the-hipster-effect-interactive/) on the blog [Pythonic Perambulations](http://jakevdp.github.io). The content is BSD licensed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week I started seeing references all over the internet to [this paper](http://arxiv.org/abs/1410.8001): *The Hipster Effect: When Anticonformists All Look The Same*. It essentially describes a simple mathematical model which models conformity and non-conformity among a mutually interacting population, and finds some interesting results: namely, **conformity among a population of self-conscious non-conformists is similar to a phase transition in a time-delayed thermodynamic system**. In other words, with enough hipsters around responding to delayed fashion trends, a plethora of facial hair and fixed gear bikes is a natural result.\n",
    "\n",
    "Also naturally, upon reading the paper I wanted to try to reproduce the work. The paper solves the problem analytically for a continuous system and shows the precise values of certain phase transitions within the long-term limit of the postulated system. Though such theoretical derivations are useful, I often find it more intuitive to simulate systems like this in a more approximate manner to gain hands-on understanding. By the end of this notebook, we'll be using IPython's incredible [interactive widgets](http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Interactive%20Widgets/Index.ipynb) to explore how the inputs to this model affect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "\n",
    "* [Think Python](http://www.greenteapress.com/thinkpython/thinkpython.pdf)\n",
    "* [MIT Open Courseware: A Gentle Introduction to Programming Using Python](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2008/index.htm)\n",
    "* [Learn Python the Hard Way](http://learnpythonthehardway.org/book/)\n",
    "* [Python Koans](https://github.com/gregmalcolm/python_koans/wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modified Stylesheet for notebook.\n",
    "# from IPython.core.display import HTML\n",
    "# def css_styling():\n",
    "#     styles = open(\"../custom_nb_style.css\", \"r\").read()\n",
    "#     return HTML(styles)\n",
    "\n",
    "# css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "# import the Image display module\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Project Overview___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.cambridgeshireinsight.org.uk/files/caminsight/resize/widerdeterminants-500x337.jpg\" height=\"50\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://www.cambridgeshireinsight.org.uk/files/caminsight/resize/widerdeterminants-500x337.jpg', height=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#project overview text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#project overview viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#project overview viz text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "> ###From an at-risk patient's perspective, where are the gaps in care?\n",
    "> ###Ultimately, where are the opportunities for improved system management for most at-risk enrollees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"goals\"></a>\n",
    "###Goal\n",
    "\n",
    "Let's ask further questions to better define what we hope to achieve.\n",
    "\n",
    "> ####Exploratory Analysis\n",
    "\n",
    "> What factors are associated with poor and good health status?\n",
    "\n",
    "> Are there any general patterns in comorbidity?\n",
    "\n",
    "> What is the impact of pain on physical and mental quality of living?\n",
    "\n",
    "> What is the relationship between mental health and presence of multiple chronic conditions?\n",
    "\n",
    "> Regional Differences?\n",
    "\n",
    "> ####Cohort Analysis\n",
    "\n",
    "> Among Medicare enrollees, which patients are among the most at-risk?\n",
    "\n",
    "> What are there corresponding demographic and outcomes profiles on total health dimensions?\n",
    "\n",
    "> How does an individual enrollee's profile compare to Medicaid population?\n",
    "\n",
    "> ####Predictive Modeling\n",
    "\n",
    "> Can we approximate/predict a new enrollee's profile from historical data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##___Acquire___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data comes from an HOS Outcomes Survey from 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphic of data dictionary - pre clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphic of data dictionary - post clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Raw data from [hosonline.org](hosonline.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C01000060,3, ,2,1,1,1,4,1,1,4,4,3,3,3,4,5,5,4,3,3,1,1,1,2,2,1,1,1,1, 6, 0, 0,2,1,2,2,4,1,2,2,2,2,2,1,2,1,1,1,2,2,2,2, , , , , ,4,3, 6,1,1,4,3,2, , , ,1,1,2,2,1,1,1,1,M10,M1, 97.3,C16, 8,1\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 source_data/C16B_PUF.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Final Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original data major components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of XXXX elements comprised of XXXX unique songs from XXXX artists, spanning   XXX weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# songs = pd.read_csv('gist')\n",
    "# songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##___Explore Data___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(songs[['popularity','danceability','duration','tempo','loudness','energy']],figsize=(20,20))\n",
    "plt.suptitle('Scatterplot Matrix of Song Attributes',size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rock = rock.dropna()\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(features)):\n",
    "    v = i +1\n",
    "    ax1 = subplot(5,2,v)\n",
    "    ax1.hist(rock[features[i]])\n",
    "    ax1.set_title(str(features[i]),fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#explanatory text of data attributes: mean, variance spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the randomness of the scatterplots, the histograms of the features were almost normally distributed.  I found the distribution of the data to be surprising considering the weekly top 40 is a seemingly random collection of songs with no real relation to one another.\n",
    "\n",
    "Furthermore, the scatterplots indicated that there would be a lot of noise in the data, given the wide range of song attributes.  The way to analyze the data, I determined, would be to use subsets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Plotting Large Correlation Matrix\"\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.corrplot(profiles_simple, annot=False, sig_stars=False,\n",
    "             diag_names=False, cmap=cmap, ax=ax)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Initial Analysis - Cluster Analysis___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text How would we visually segment?  We will compare this later to clustering technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show math:\n",
    "    \n",
    "$$\n",
    "\\phi(x;\\beta) = \\frac{1 + \\tanh(\\beta \\cdot x)}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and score my model, I used a train/test split, which, as the name implies, breaks the dataset up into a training set and a testing set.  The training set is fed into the model to 'teach' the feature variations and their relationship to the target variable and the test set is used to simulate new data that the computer has not seen.  The computer will then score how well the model performs.  In the case of the OLS model, the computer will provide R-Squared values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "km = KMeans(n_clusters=5, random_state=1)\n",
    "km.fit(profiles_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_simple['persona'] = km.predict(profiles_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_simple.groupby(by='persona').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_simple[profiles_simple.persona == 4].hist(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_simple[profiles_simple.persona == 2].hist(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_simple[profiles_simple.persona == 1].hist(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some things to note about our goals and approach:\n",
    "\n",
    "* Determine what deﬁnes __success__, and to what degree.\n",
    "* Brainstorm __metrics__ to visualize and/or calculate.\n",
    "* Ask __questions__ that have (or can have) a definitive answer.\n",
    "* Be careful what you wish for, be aware of possible __correlations__, and take caution with how you [measure](http://en.wikipedia.org/wiki/Observer-expectancy_effect) it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Scoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Train Score: ', model.score(xtrain,ytrain)\n",
    "# print 'Test Score: ', model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and test scores indicate a relatively poor linear fit for the metadata features and elapsed time vs the target value of popularity.  As expected, the model does not show signs of overfitting as the test and train score values are nearly identical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Examing Model & Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#four groups boxplots plotted next to each other.\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(features)):\n",
    "    v = i +1\n",
    "    ax1 = rock.boxplot(features[i],by='decade',ax=subplot(5,2,v))\n",
    "    ax1.set_title(str(features[i]),fontsize=15)\n",
    "    ax1.set_xlabel('')\n",
    "plt.suptitle('Rock Feature Boxplots by Decade',size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compare this clustering to just using quartiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the boxplots, songs in the top median quantile of popularity demonstrate a slightly higher level of verbosity, energy, and loudness than songs in the lower median quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pros & Cons of other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examination of the training set, the target values are skewed towards the earlier decades in the dataset.  With the high variation in the data, a Naïve Bayes model, although a strong algorithm, will not pick up on the nuances in the song metadata to make effective predictions to the song’s decade of origin.  This is because Naive Bayes assumes that all features are independent of one another.\n",
    "\n",
    "In place of Naïve Bayes, I will use a Random Forest model.  Although very prone to overfitting on the training set in machine learning models, this model is strong enough to pick up on the subtle variations in the data, as it does not perceive all of the features to be in a vacuum like the Bayes algorithm.  Moreover, as the rock song dataset only consists of 5,056 unique songs, scaling with hundreds decision trees should not prove to be an issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the use of song metadata for the Billboard Top 40 for the past half century and OLS, Logistic, Random Forest, and K-Means machine learning algorithms, I determined that time plays a larger role in the popularity attrition of a song than any metadata factor in an OLS linear model.  Using a categorial logistic regression model, however, I found that loudness, energy, and danceability, to some extent, account for some of the gains in song popularity. \n",
    "\n",
    "Moreover, depending on the strength of the algorithm used, song metadata can be a decent predictor to determine from which decade a particular song comes.  The metadata truly shines, however, in the classification and clustering of genres.  In developing my own genre clusters with K-Means, I was amazed how accurately the computer picked like-sounding songs through only 5 feature attributes.  \n",
    "\n",
    "As the genre area plot demonstrated, we as a culture are getting more diverse in terms of the music to which we listen.  With the power of machine learning, however, services like Spotify, Google Music, and Pandora will never be at a loss for songs to meet a particular individual’s tastes, despite the ever increasing scope of possibilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information please visit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more code and the datasets for this project, please visit my GitHub page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import HTML\n",
    "# styles = open(\"custom_dark.css\", \"r\").read()\n",
    "# HTML(styles)\n",
    "\n",
    "##### For prettier graphs see http://localhost:8888/notebooks/project/iPython%20notebook%20gallery/Up%20and%20Down%20PyData%202014.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
